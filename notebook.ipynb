{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23347,"status":"ok","timestamp":1749742693098,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"do_zcIkpRy-i","outputId":"4ac0f26d-b272-4630-ca49-15a655c6a549"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras_cv\n","  Downloading keras_cv-0.9.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_cv) (24.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras_cv) (1.4.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras_cv) (2024.11.6)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras_cv) (4.9.9)\n","Collecting keras-core (from keras_cv)\n","  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras_cv) (0.3.12)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub-\u003ekeras_cv) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub-\u003ekeras_cv) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub-\u003ekeras_cv) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core-\u003ekeras_cv) (2.0.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core-\u003ekeras_cv) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core-\u003ekeras_cv) (0.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core-\u003ekeras_cv) (3.13.0)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core-\u003ekeras_cv) (0.1.9)\n","Requirement already satisfied: array_record\u003e=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (0.7.2)\n","Requirement already satisfied: etils\u003e=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (1.12.2)\n","Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (4.2.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (2.3)\n","Requirement already satisfied: protobuf\u003e=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (5.29.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (5.9.5)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (18.1.0)\n","Requirement already satisfied: simple_parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (0.1.7)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (1.17.1)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (3.1.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (0.10.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets-\u003ekeras_cv) (1.17.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (0.8.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (2025.3.2)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (6.5.2)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (4.14.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]\u003e=1.9.1; python_version \u003e= \"3.11\"-\u003etensorflow-datasets-\u003ekeras_cv) (3.22.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ekagglehub-\u003ekeras_cv) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ekagglehub-\u003ekeras_cv) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ekagglehub-\u003ekeras_cv) (2.4.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ekagglehub-\u003ekeras_cv) (2025.4.26)\n","Requirement already satisfied: attrs\u003e=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree-\u003ekeras-core-\u003ekeras_cv) (25.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise-\u003etensorflow-datasets-\u003ekeras_cv) (1.17.0)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras-core-\u003ekeras_cv) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich-\u003ekeras-core-\u003ekeras_cv) (2.19.1)\n","Requirement already satisfied: docstring-parser\u003c1.0,\u003e=0.15 in /usr/local/lib/python3.11/dist-packages (from simple_parsing-\u003etensorflow-datasets-\u003ekeras_cv) (0.16)\n","Requirement already satisfied: googleapis-common-protos\u003c2,\u003e=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata-\u003etensorflow-datasets-\u003ekeras_cv) (1.70.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras-core-\u003ekeras_cv) (0.1.2)\n","Downloading keras_cv-0.9.0-py3-none-any.whl (650 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras-core, keras_cv\n","Successfully installed keras-core-0.1.7 keras_cv-0.9.0\n"]}],"source":["!pip install keras_cv"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":19442,"status":"ok","timestamp":1749742712546,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"xeqIVYRoAf0R"},"outputs":[],"source":["from pathlib import Path\n","\n","import kagglehub\n","import keras_cv\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.applications.mobilenet_v2 import (\n","    preprocess_input as mobilenet_preprocess_input,\n",")\n","from tensorflow.keras.callbacks import (\n","    EarlyStopping,\n","    ModelCheckpoint,\n","    ReduceLROnPlateau,\n","    TensorBoard,\n",")\n","\n","AUTOTUNE = tf.data.AUTOTUNE"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3253,"status":"ok","timestamp":1749742715803,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"sRTyRfOIScGf","outputId":"14fddad7-b949-4de4-fb0e-5294a3eb7d70"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using dataset from: /kaggle/input/plant-village/PlantVillage\n"]}],"source":["DATA_DIR = kagglehub.dataset_download(\"arjuntejaswi/plant-village\")\n","DATA_PATH = Path(DATA_DIR) / \"PlantVillage\"\n","\n","print(f\"Using dataset from: {DATA_PATH}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16962,"status":"ok","timestamp":1749742732768,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"JLCTV7_1SiI5","outputId":"5cdd4d03-1130-4b75-efcd-665c7239bcb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20638 files belonging to 15 classes.\n","Using 16511 files for training.\n","Found 20638 files belonging to 15 classes.\n","Using 4127 files for validation.\n","Number of classes: 15\n","Class names: ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite', 'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus', 'Tomato__Tomato_mosaic_virus', 'Tomato_healthy']\n","Training dataset size: 516 batches\n","Validation dataset size: 129 batches\n"]}],"source":["# Configuration\n","IMG_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","SEED = 42\n","VALIDATION_SPLIT = 0.2\n","\n","# Load and split data\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    DATA_PATH,\n","    label_mode=\"int\",\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    seed=SEED,\n","    shuffle=True,\n","    validation_split=VALIDATION_SPLIT,\n","    subset=\"training\",\n",")\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    DATA_PATH,\n","    label_mode=\"int\",\n","    image_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    seed=SEED,\n","    shuffle=True,\n","    validation_split=VALIDATION_SPLIT,\n","    subset=\"validation\",\n",")\n","\n","class_names = train_ds.class_names\n","num_classes = len(class_names)\n","\n","# Prefetching\n","train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","print(f\"Number of classes: {num_classes}\")\n","print(f\"Class names: {class_names}\")\n","print(\n","    f\"Training dataset size: {tf.data.experimental.cardinality(train_ds).numpy()} batches\"\n",")\n","print(\n","    f\"Validation dataset size: {tf.data.experimental.cardinality(val_ds).numpy()} batches\"\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1749742733320,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"5fJv_fL7SjRR"},"outputs":[],"source":["augmenter = keras.Sequential(\n","    [\n","        keras_cv.layers.RandomFlip(\"horizontal\"),\n","        keras_cv.layers.RandomRotation(factor=0.1),\n","        keras_cv.layers.RandomZoom(height_factor=0.1, width_factor=0.1),\n","        keras_cv.layers.RandomContrast(factor=0.1, value_range=(0, 255)),\n","    ],\n","    name=\"augmenter\",\n",")\n","\n","\n","def preprocess_data(\n","    images: tf.Tensor, labels: tf.Tensor\n",") -\u003e tuple[tf.Tensor, tf.Tensor]:\n","    \"\"\"Applies augmentation to images.\"\"\"\n","    augmented_images = augmenter(images)\n","    return augmented_images, labels\n","\n","\n","train_ds = train_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2308,"status":"ok","timestamp":1749742735627,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"3YrI8kKkSlRD","outputId":"fb863afb-a049-428d-cb76-7c5c127dabe1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["# Base Model\n","base_model = keras.applications.MobileNetV2(\n","    input_shape=(*IMG_SIZE, 3),\n","    include_top=False,\n","    weights=\"imagenet\",\n",")\n","base_model.trainable = False\n","\n","# Build the new model\n","inputs = keras.Input(shape=(*IMG_SIZE, 3), name=\"input_layer\")\n","x = mobilenet_preprocess_input(inputs)\n","x = base_model(x, training=False)\n","x = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n","x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n","outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n","\n","model = keras.Model(inputs, outputs, name=\"plant_disease_classifier\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1749742735673,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"Rzdcx5qsSmvb","outputId":"dff2abd6-209f-47f2-cd6f-f2ede11a6d2e"},"outputs":[{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"plant_disease_classifier\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"plant_disease_classifier\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)                    \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape           \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e       Param # \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ true_divide (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eTrueDivide\u003c/span\u003e)        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ subtract (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eSubtract\u003c/span\u003e)             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)     │     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,257,984\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eFunctional\u003c/span\u003e)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling          │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eGlobalAveragePooling2D\u003c/span\u003e)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)         │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e)             │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e19,215\u003c/span\u003e │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ true_divide (\u001b[38;5;33mTrueDivide\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ subtract (\u001b[38;5;33mSubtract\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │        \u001b[38;5;34m19,215\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,277,199\u003c/span\u003e (8.69 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,277,199\u001b[0m (8.69 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e19,215\u003c/span\u003e (75.06 KB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,215\u001b[0m (75.06 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,257,984\u003c/span\u003e (8.61 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1749742735679,"user":{"displayName":"Rifzki Adiyaksa A314YBF428","userId":"14684262034536255169"},"user_tz":-420},"id":"qInSGRqBAf0Y"},"outputs":[],"source":["LOG_DIR = \"logs\"\n","Path(LOG_DIR).mkdir(parents=True, exist_ok=True)\n","\n","# Callbacks\n","model_checkpoint_cb = ModelCheckpoint(\n","    filepath=Path(LOG_DIR) / \"transfer_learning\" / \"best_model.keras\",\n","    save_best_only=True,\n","    monitor=\"val_accuracy\",\n","    mode=\"max\",\n","    verbose=1,\n",")\n","\n","early_stopping_cb = EarlyStopping(\n","    patience=5, restore_best_weights=True, monitor=\"val_loss\", mode=\"min\", verbose=1\n",")\n","\n","reduce_lr_on_plateau_cb = ReduceLROnPlateau(\n","    patience=3, factor=0.5, verbose=1, monitor=\"val_loss\", mode=\"min\"\n",")\n","\n","tensorboard_cb_tl = TensorBoard(log_dir=Path(LOG_DIR) / \"transfer_learning\")\n","\n","transfer_learning_callbacks = [\n","    model_checkpoint_cb,\n","    early_stopping_cb,\n","    reduce_lr_on_plateau_cb,\n","    tensorboard_cb_tl,\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"sbzBXETZAf0Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.5929 - loss: 1.3065\n","Epoch 1: val_accuracy improved from -inf to 0.85268, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 419ms/step - accuracy: 0.5931 - loss: 1.3056 - val_accuracy: 0.8527 - val_loss: 0.4683 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.8367 - loss: 0.5072\n","Epoch 2: val_accuracy improved from 0.85268 to 0.87667, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 366ms/step - accuracy: 0.8367 - loss: 0.5072 - val_accuracy: 0.8767 - val_loss: 0.3867 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8620 - loss: 0.4266\n","Epoch 3: val_accuracy did not improve from 0.87667\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 363ms/step - accuracy: 0.8620 - loss: 0.4266 - val_accuracy: 0.8755 - val_loss: 0.3644 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.8688 - loss: 0.3937\n","Epoch 4: val_accuracy improved from 0.87667 to 0.89217, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 374ms/step - accuracy: 0.8688 - loss: 0.3937 - val_accuracy: 0.8922 - val_loss: 0.3297 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.8693 - loss: 0.3794\n","Epoch 5: val_accuracy improved from 0.89217 to 0.89847, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 368ms/step - accuracy: 0.8694 - loss: 0.3794 - val_accuracy: 0.8985 - val_loss: 0.3117 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8795 - loss: 0.3586\n","Epoch 6: val_accuracy did not improve from 0.89847\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 363ms/step - accuracy: 0.8795 - loss: 0.3586 - val_accuracy: 0.8956 - val_loss: 0.3124 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.8853 - loss: 0.3354\n","Epoch 7: val_accuracy did not improve from 0.89847\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 362ms/step - accuracy: 0.8853 - loss: 0.3354 - val_accuracy: 0.8968 - val_loss: 0.3138 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.8831 - loss: 0.3492\n","Epoch 8: val_accuracy improved from 0.89847 to 0.90235, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 365ms/step - accuracy: 0.8831 - loss: 0.3492 - val_accuracy: 0.9024 - val_loss: 0.2914 - learning_rate: 0.0010\n","Epoch 9/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8947 - loss: 0.3200\n","Epoch 9: val_accuracy did not improve from 0.90235\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 361ms/step - accuracy: 0.8946 - loss: 0.3200 - val_accuracy: 0.9004 - val_loss: 0.2866 - learning_rate: 0.0010\n","Epoch 10/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8888 - loss: 0.3241\n","Epoch 10: val_accuracy did not improve from 0.90235\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 361ms/step - accuracy: 0.8888 - loss: 0.3241 - val_accuracy: 0.9019 - val_loss: 0.2947 - learning_rate: 0.0010\n","Epoch 11/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.8883 - loss: 0.3262\n","Epoch 11: val_accuracy improved from 0.90235 to 0.90477, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 363ms/step - accuracy: 0.8883 - loss: 0.3262 - val_accuracy: 0.9048 - val_loss: 0.2881 - learning_rate: 0.0010\n","Epoch 12/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8894 - loss: 0.3227\n","Epoch 12: val_accuracy did not improve from 0.90477\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 364ms/step - accuracy: 0.8894 - loss: 0.3227 - val_accuracy: 0.9036 - val_loss: 0.2756 - learning_rate: 0.0010\n","Epoch 13/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8909 - loss: 0.3179\n","Epoch 13: val_accuracy improved from 0.90477 to 0.91350, saving model to logs/transfer_learning/best_model.keras\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 361ms/step - accuracy: 0.8909 - loss: 0.3179 - val_accuracy: 0.9135 - val_loss: 0.2672 - learning_rate: 0.0010\n","Epoch 14/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.8928 - loss: 0.3109\n","Epoch 14: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 364ms/step - accuracy: 0.8928 - loss: 0.3109 - val_accuracy: 0.9082 - val_loss: 0.2842 - learning_rate: 0.0010\n","Epoch 15/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.8926 - loss: 0.3105\n","Epoch 15: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 358ms/step - accuracy: 0.8926 - loss: 0.3105 - val_accuracy: 0.9096 - val_loss: 0.2660 - learning_rate: 0.0010\n","Epoch 16/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.8911 - loss: 0.3152\n","Epoch 16: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 366ms/step - accuracy: 0.8911 - loss: 0.3152 - val_accuracy: 0.9091 - val_loss: 0.2786 - learning_rate: 0.0010\n","Epoch 17/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8908 - loss: 0.3067\n","Epoch 17: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 359ms/step - accuracy: 0.8908 - loss: 0.3067 - val_accuracy: 0.8985 - val_loss: 0.3094 - learning_rate: 0.0010\n","Epoch 18/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8968 - loss: 0.3005\n","Epoch 18: val_accuracy did not improve from 0.91350\n","\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 361ms/step - accuracy: 0.8968 - loss: 0.3005 - val_accuracy: 0.9043 - val_loss: 0.2884 - learning_rate: 0.0010\n","Epoch 19/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.8994 - loss: 0.2965\n","Epoch 19: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 363ms/step - accuracy: 0.8994 - loss: 0.2964 - val_accuracy: 0.9123 - val_loss: 0.2622 - learning_rate: 5.0000e-04\n","Epoch 20/20\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.9034 - loss: 0.2867\n","Epoch 20: val_accuracy did not improve from 0.91350\n","\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 360ms/step - accuracy: 0.9034 - loss: 0.2867 - val_accuracy: 0.9079 - val_loss: 0.2660 - learning_rate: 5.0000e-04\n","Restoring model weights from the end of the best epoch: 19.\n"]}],"source":["EPOCHS_TRANSFER_LEARNING = 20\n","\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=EPOCHS_TRANSFER_LEARNING,\n","    callbacks=transfer_learning_callbacks,\n","    verbose=1,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lF_g4CWVAf0Z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trainable variables after unfreezing: 158\n"]},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"plant_disease_classifier\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"plant_disease_classifier\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)                    \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape           \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e       Param # \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ true_divide (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eTrueDivide\u003c/span\u003e)        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ subtract (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eSubtract\u003c/span\u003e)             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)     │     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,257,984\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eFunctional\u003c/span\u003e)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling          │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eGlobalAveragePooling2D\u003c/span\u003e)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)         │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output_layer (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e15\u003c/span\u003e)             │        \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e19,215\u003c/span\u003e │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ true_divide (\u001b[38;5;33mTrueDivide\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ subtract (\u001b[38;5;33mSubtract\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │        \u001b[38;5;34m19,215\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,277,199\u003c/span\u003e (8.69 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,277,199\u001b[0m (8.69 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,243,087\u003c/span\u003e (8.56 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,243,087\u001b[0m (8.56 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e34,112\u003c/span\u003e (133.25 KB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m34,112\u001b[0m (133.25 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["base_model.trainable = True\n","\n","print(f\"Trainable variables after unfreezing: {len(model.trainable_variables)}\")\n","\n","# Re-compile with a lower learning rate\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"],\n",")\n","model.summary()\n","\n","# Callbacks for Fine-tuning\n","model_checkpoint_cb_ft = ModelCheckpoint(\n","    filepath=Path(LOG_DIR) / \"fine_tuning\" / \"best_model.keras\",\n","    save_best_only=True,\n","    monitor=\"val_accuracy\",\n","    mode=\"max\",\n","    verbose=1,\n",")\n","tensorboard_cb_ft = TensorBoard(log_dir=Path(LOG_DIR) / \"fine_tuning\")\n","\n","fine_tuning_callbacks = [\n","    model_checkpoint_cb_ft,\n","    early_stopping_cb,\n","    reduce_lr_on_plateau_cb,\n","    tensorboard_cb_ft,\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2VNYlZ_Af0a"},"outputs":[],"source":["print(\"Evaluating final model on the validation set:\")\n","loss, accuracy = model.evaluate(val_ds, verbose=0)\n","print(f\"  Validation Loss: {loss:.4f}\")\n","print(f\"  Validation Accuracy: {accuracy * 100:.2f}%\\n\")\n","\n","# Generate predictions for Confusion Matrix\n","val_labels_list = []\n","for _, labels_batch in val_ds:\n","    val_labels_list.append(labels_batch)\n","val_true_labels = tf.concat(val_labels_list, axis=0).numpy()\n","\n","val_pred_probs = model.predict(val_ds, verbose=0)\n","val_pred_labels = tf.argmax(val_pred_probs, axis=1).numpy()\n","\n","# Plot Confusion Matrix\n","cm = confusion_matrix(val_true_labels, val_pred_labels)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n","\n","fig, ax = plt.subplots(figsize=(12, 12))\n","disp.plot(xticks_rotation=90, cmap=\"Blues\", ax=ax, values_format=\"d\")\n","plt.title(\"Confusion Matrix (After Fine-tuning)\")\n","plt.grid(False)\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YIKsHfjtAf0a"},"outputs":[],"source":["FINAL_MODEL_PATH = \"best_model.keras\"\n","model.save(FINAL_MODEL_PATH)\n","print(f\"Final model saved to: {FINAL_MODEL_PATH}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhmIv6DBA-CT"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.12"}},"nbformat":4,"nbformat_minor":0}